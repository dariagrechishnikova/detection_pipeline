# -*- coding: utf-8 -*-
"""data_provider.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15zegQhVM2kYWQ1G61M-O3Zj_qm9x5EfJ
"""

import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard
from tensorflow.keras.optimizers import Adam
from dataclasses import dataclass
from runner import *
from trainer import *
from initial_parser import *
from splitter import *
from custom_models import *
from custom_metrics import *
from custom_losses import *
from iterstrat.ml_stratifiers import MultilabelStratifiedKFold
from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit
import os
import random
from tensorflow.keras.layers.experimental import preprocessing 
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import albumentations as A
import numpy as np
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from keras.layers import BatchNormalization
from keras.layers.core import SpatialDropout2D, Activation
from tensorflow.keras.applications import EfficientNetB0
from keras import backend as K
from keras.layers.merge import concatenate
from keras.utils.data_utils import get_file
from tensorflow import keras
import segmentation_models as sm
import cv2
import datetime
from segmentation_models.losses import bce_jaccard_loss







class data_provider_insteg():
  def __init__(self, input_data_path, input_label_path, input_buffer_size, input_batch_size, input_parser, input_augmentor):
      self.path_image = input_data_path
      self.path_mask = input_label_path
      self.buffer_size = input_buffer_size
      self.batch_size = input_batch_size
      self.parser = input_parser
      self.augmentor = input_augmentor

  def configure_train_ds(self, train_images_ds):
    train_batches = (
        train_images_ds
        .cache()
        .shuffle(self.buffer_size)
        #.map(self.augmentor.tf_augment)
        .batch(self.batch_size)
        .repeat()
        .prefetch(buffer_size=tf.data.AUTOTUNE))
    return train_batches

  def configure_val_ds(self, test_images_ds):
    return test_images_ds.batch(self.batch_size)


  def create_tf_dataset(self, index_list):
    random.shuffle(index_list)
    filenames_ds = tf.data.Dataset.from_tensor_slices(index_list)

    images_ds = filenames_ds.map(self.parser.parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    masks_ds = filenames_ds.map(self.parser.parse_mask, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    ds = tf.data.Dataset.zip((images_ds, masks_ds))

    '''cnt = 0
    for el in ds:
      print()
      try:
        print(el)
        cnt += 1
      except:
        print(f'Processed {cnt} values')'''

    return ds

  def get_train_tfset(self, index_list):
    return self.configure_train_ds(self.create_tf_dataset(index_list))

  def get_val_tfset(self, index_list):
    return self.configure_val_ds(self.create_tf_dataset(index_list))



#CHECKS. Visualize tf.data.dataset elements
def display(display_list):
  plt.figure(figsize=(15, 15))

  title = ['Input Image', 'True Mask']

  for i in range(len(display_list)):
    plt.subplot(1, len(display_list), i+1)
    plt.title(title[i])
    if i == 0:
      plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))
    else:
      plt.imshow(display_list[i], cmap='gray')
    plt.axis('off')
  plt.show()


def plot_n_elements(ds,n):
  for images, masks in ds.take(n):
    print(images.shape, masks.shape)
    sample_image, sample_mask = images[0], masks[0]
    display([sample_image, sample_mask])
    #display([sample_image, sample_mask[:,:,0], sample_mask[:,:,1], sample_mask[:,:,2], sample_mask[:,:,3]])
  return

def plot_n_distributions(ds,n):
  for images, masks in ds.take(n):
    print('mask shape',masks.shape)
    print('images shape',images.shape)
    sample_image, sample_mask = images[0], masks[0]
    plot_image = tf.reshape(sample_image,150528)
    plt.hist(plot_image)
    plt.show()
    plot_mask = tf.reshape(sample_mask,50176)
    plt.hist(plot_mask)
    plt.show()
  return

#plot_n_elements(data,2)






class parser_insteg():
  def __init__(self, input_path_image, input_path_mask, input_height, input_width):
    self.path_image = input_path_image
    self.path_mask = input_path_mask
    self.height = input_height
    self.width = input_width


  def get_boxed_shapes(self, image):
    box_shape = tf.shape(image)
    if box_shape[2] == 3:
      h_w_tensor = tf.constant([self.height, self.width,3])
    else:
      h_w_tensor = tf.constant([self.height, self.width,1])
    left_pre_pad_tensor = (h_w_tensor - box_shape) // 2
    additional_padding = (h_w_tensor - box_shape) % 2
    right_pre_pad_tensor = left_pre_pad_tensor + additional_padding
    return left_pre_pad_tensor, right_pre_pad_tensor
    


  def parse_image(self, filename):
    image = tf.io.read_file(self.path_image + filename)
    image = tf.image.decode_png(image, channels=3)
    left_pre_pad_tensor, right_pre_pad_tensor = self.get_boxed_shapes(image = image)
    left_pre_pad_tensor = tf.reshape(left_pre_pad_tensor, (-1, 1)) # to make it column
    right_pre_pad_tensor = tf.reshape(right_pre_pad_tensor, (-1, 1)) # to make it column
    paddings = tf.concat([left_pre_pad_tensor, right_pre_pad_tensor],1)
    image = tf.image.adjust_contrast(image, 2.)
    image = tf.pad(image, paddings, mode='CONSTANT', constant_values=0)
    image = image / 255
    return image

  def parse_mask(self, filename):
    mask = tf.io.read_file(self.path_mask + filename)
    mask = tf.image.decode_png(mask)
    left_pre_pad_tensor, right_pre_pad_tensor = self.get_boxed_shapes(image = mask)
    left_pre_pad_tensor = tf.reshape(left_pre_pad_tensor, (-1, 1)) # to make it column
    right_pre_pad_tensor = tf.reshape(right_pre_pad_tensor, (-1, 1)) # to make it column
    paddings = tf.concat([left_pre_pad_tensor, right_pre_pad_tensor],1)
    mask = tf.pad(mask, paddings, mode='CONSTANT', constant_values=0)
    mask = tf.cast(mask, tf.float32)
    return tf.squeeze(mask)
    
  def test(self):
    image = tf.constant(np.zeros(shape=(20, 20, 3), dtype=np.uint8))
    pre_pad = self.get_boxed_shapes(image)
    print(pre_pad)

    pre_pat_t = tf.transpose(pre_pad)
    print(pre_pat_t)



class augmentor_insteg():
  def __init__(self):
    self.transforms = A.Compose([
                                 A.HorizontalFlip(p=0.5),
                                 A.VerticalFlip(p=0.5),
                                 A.RandomRotate90(p=0.5),
                                 A.Transpose(p=0.5),
                                 ])

  def aug_fn(self, image, mask):
    transformed = self.transforms(image=image, masks=mask)
    transformed_image = transformed['image']
    transformed_mask = transformed['mask']
    return transformed_image, transformed_mask

  def tf_augment(self, image, mask):
    im_shape = image.shape
    msk_shape = mask.shape
    #print(f"Inside tf_aug_fn: image.shape = {image.shape}, mask.shape = {mask.shape}")
    [aug_image, aug_mask] = tf.numpy_function(self.aug_fn, [image, mask], [tf.float32, tf.float32])
    aug_image.set_shape(im_shape)
    aug_mask.set_shape(msk_shape)
    return aug_image, aug_mask





class target_transforms():
  @tf.function
  def transform_targets_for_output(y_true, grid_size, anchor_idxs):
    # y_true: (N, boxes, (x1, y1, x2, y2, class, best_anchor))
    N = tf.shape(y_true)[0]

    # y_true_out: (N, grid, grid, anchors, [x1, y1, x2, y2, obj, class])
    y_true_out = tf.zeros(
        (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))

    anchor_idxs = tf.cast(anchor_idxs, tf.int32)

    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)
    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)
    idx = 0
    for i in tf.range(N):
        for j in tf.range(tf.shape(y_true)[1]):
            if tf.equal(y_true[i][j][2], 0):
                continue
            anchor_eq = tf.equal(
                anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))

            if tf.reduce_any(anchor_eq):
                box = y_true[i][j][0:4]
                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2

                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)
                grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)

                # grid[y][x][anchor] = (tx, ty, bw, bh, obj, class)
                indexes = indexes.write(
                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])
                updates = updates.write(
                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])
                idx += 1

    # tf.print(indexes.stack())
    # tf.print(updates.stack())

    return tf.tensor_scatter_nd_update(
        y_true_out, indexes.stack(), updates.stack())


  def transform_targets(y_train, anchors, anchor_masks, size):
    y_outs = []
    grid_size = size // 32

    # calculate anchor index for true boxes
    anchors = tf.cast(anchors, tf.float32)
    anchor_area = anchors[..., 0] * anchors[..., 1]
    box_wh = y_train[..., 2:4] - y_train[..., 0:2]
    box_wh = tf.tile(tf.expand_dims(box_wh, -2),
                     (1, 1, tf.shape(anchors)[0], 1))
    box_area = box_wh[..., 0] * box_wh[..., 1]
    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * \
        tf.minimum(box_wh[..., 1], anchors[..., 1])
    iou = intersection / (box_area + anchor_area - intersection)
    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)
    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)

    y_train = tf.concat([y_train, anchor_idx], axis=-1)

    for anchor_idxs in anchor_masks:
        y_outs.append(transform_targets_for_output(
            y_train, grid_size, anchor_idxs))
        grid_size *= 2

    return tuple(y_outs)


  def transform_images(x_train, size):
    x_train = tf.image.resize(x_train, (size, size))
    x_train = x_train / 255
    return x_train


  



class parser():
  def


class augment():
  def


class data_povider():
  def __init__(self):
    self.IMAGE_FEATURE_MAP = {
    'image/encoded': tf.io.FixedLenFeature([], tf.string),
    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),
    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),
    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),
    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),
    'image/object/class/text': tf.io.VarLenFeature(tf.string),
    }
    self.tt_obj = target_transforms()

  def parse_tfrecord(self, tfrecord, class_table, size):
    x = tf.io.parse_single_example(tfrecord, self.IMAGE_FEATURE_MAP)
    x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)
    x_train = tf.image.resize(x_train, (size, size))

    class_text = tf.sparse.to_dense(
        x['image/object/class/text'], default_value='')
    labels = tf.cast(class_table.lookup(class_text), tf.float32)
    y_train = tf.stack([tf.sparse.to_dense(x['image/object/bbox/xmin']),
                        tf.sparse.to_dense(x['image/object/bbox/ymin']),
                        tf.sparse.to_dense(x['image/object/bbox/xmax']),
                        tf.sparse.to_dense(x['image/object/bbox/ymax']),
                        labels], axis=1)

    paddings = [[0, FLAGS.yolo_max_boxes - tf.shape(y_train)[0]], [0, 0]]
    y_train = tf.pad(y_train, paddings)

    return x_train, y_train


  def load_tfrecord_dataset(self, file_pattern, class_file, size=416):
    LINE_NUMBER = -1  # TODO: use tf.lookup.TextFileIndex.LINE_NUMBER
    class_table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(
        class_file, tf.string, 0, tf.int64, LINE_NUMBER, delimiter="\n"), -1)

    files = tf.data.Dataset.list_files(file_pattern)
    dataset = files.flat_map(tf.data.TFRecordDataset)
    return dataset.map(lambda x: self.parse_tfrecord(x, class_table, size))


  def get_train(self):
    train_dataset = self.load_tfrecord_dataset(FLAGS.dataset, FLAGS.classes, FLAGS.size)
    train_dataset = train_dataset.shuffle(buffer_size=512)
    train_dataset = train_dataset.batch(FLAGS.batch_size)
    train_dataset = train_dataset.map(lambda x, y: (
        self.tt_obj.transform_images(x, FLAGS.size),
        self.tt_obj.transform_targets(y, anchors, anchor_masks, FLAGS.size)))
    train_dataset = train_dataset.prefetch(
        buffer_size=tf.data.experimental.AUTOTUNE)
    return train_dataset

  def get_val(self):
    val_dataset = self.load_tfrecord_dataset(FLAGS.val_dataset, FLAGS.classes, FLAGS.size)
    val_dataset = val_dataset.batch(FLAGS.batch_size)
    val_dataset = val_dataset.map(lambda x, y: (
        self.tt_obj.transform_images(x, FLAGS.size),
        self.tt_obj.transform_targets(y, anchors, anchor_masks, FLAGS.size)))
    return val_dataset







  